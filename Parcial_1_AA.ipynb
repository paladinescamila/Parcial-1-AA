{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parcial_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUgPsx-h9HCV"
      },
      "source": [
        "# **Importación de datos y librerías**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CaIYlX534Ix"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from seaborn import heatmap\n",
        "from sklearn.preprocessing import scale, LabelEncoder, quantile_transform\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import neighbors\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# Algunas constantes\n",
        "numeric_att = ['Age', 'Height', 'Weight', 'Vegetable_Frecuency', \n",
        "                   'Day_Main_Meals','Water_Liters', 'Physical_Activity', \n",
        "                   'Use_Tecnology']\n",
        "\n",
        "categorical_att = ['Gender', 'Family_History', 'Calorie_Frecuency', \n",
        "                   'Food_Between_Meals', 'Smoke', 'Calories_Control', \n",
        "                   'Drink_Alcohol', 'Transport', 'Obesity_Level']\n",
        "\n",
        "# Carga los datos (desde un repositorio en GitHub)\n",
        "url=\"https://raw.githubusercontent.com/paladinescamila/Parcial_1/main/data.csv\"\n",
        "data = pd.read_csv(url, na_values=\" ?\")\n",
        "\n",
        "# Cambia los nombres de los atributos para poder ententerlos mejor\n",
        "data.columns = ['Gender', 'Age', 'Height', 'Weight', 'Family_History', \n",
        "                'Calorie_Frecuency', 'Vegetable_Frecuency', 'Day_Main_Meals', \n",
        "                'Food_Between_Meals', 'Smoke', 'Water_Liters', \n",
        "                'Calories_Control', 'Physical_Activity', 'Use_Tecnology', \n",
        "                'Drink_Alcohol', 'Transport', 'Obesity_Level']\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rn-tF83_R3E"
      },
      "source": [
        "# **Entendimiento de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rCDqzy234HS"
      },
      "source": [
        "# Cantidad de registros y atributos\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCca5DKp9nIP"
      },
      "source": [
        "# Tipo de los atributos\n",
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5CPtrls4e92"
      },
      "source": [
        "# Medidas de centralidad y dispersión (atributos numéricos)\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acEJOLjb4xD1"
      },
      "source": [
        "# Diagrama de cajas y bigotes (atributos númericos)\n",
        "plt.boxplot((data['Age'], data['Height'], data['Weight'], \n",
        "             data['Vegetable_Frecuency'],data['Day_Main_Meals'], \n",
        "             data['Water_Liters'], data['Physical_Activity'], \n",
        "             data['Use_Tecnology']))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l79PWEMc5ZJT"
      },
      "source": [
        "# Medidas de centralidad (atributos categóricos)\n",
        "data.mode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZM_y42LdxrK"
      },
      "source": [
        "# Distribución de los datos (atributos categóricos)\n",
        "for i in categorical_att:\n",
        "    plt.title(i)\n",
        "    plt.hist(data[i])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4soW0R05581"
      },
      "source": [
        "# Correlación (tabla)\n",
        "data.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9Z9Dk_86Ifu"
      },
      "source": [
        "# Correlación (gráfica)\n",
        "heatmap(data.corr(), square=True, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yosvs-lW6Y8a"
      },
      "source": [
        "# Datos faltantes por cada atributo\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsuH6QLB668v"
      },
      "source": [
        "# Datos atípicos de cada atributo\n",
        "for i in numeric_att:\n",
        "    plt.title(i)\n",
        "    plt.boxplot(data[i])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVpqv-jb7kyx"
      },
      "source": [
        "# Cantidad de registros por nivel de obesidad\n",
        "data['Obesity_Level'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpZjguFEalq"
      },
      "source": [
        "# Gráfica de la cantidad de registros por nivel de obesidad\n",
        "data['Obesity_Level'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bwbPvzVbiNA"
      },
      "source": [
        "# Cantidad de duplicados por nivel de obesidad\n",
        "levels = data.groupby(['Obesity_Level'])\n",
        "for name, group in levels:\n",
        "    print(name, group[group.duplicated()].count()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_59Pl4ELAiXh"
      },
      "source": [
        "# Cantidad de registros sin valores atípicos\n",
        "temp = data[numeric_att]\n",
        "temp[(np.abs(stats.zscore(temp)) < 3).all(axis=1)].count()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UiXreQ69pzi"
      },
      "source": [
        "# Cantidad de registros sin valores atípicos por clase\n",
        "levels = data.groupby(['Obesity_Level'])\n",
        "names, complete, total = [], [], []\n",
        "for name, group in levels:\n",
        "    numeric = group[numeric_att]\n",
        "    names += [name]\n",
        "    complete += [numeric[(np.abs(stats.zscore(numeric)) < 3).all(axis=1)].count()[0]]\n",
        "    total += [group.count()[0]]\n",
        "\n",
        "pd.DataFrame({'Completos': complete, 'Total':total}, index=names).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0buynKTV9Zf"
      },
      "source": [
        "### **Conclusiones sobre el entendimiento de los datos**\n",
        "En [ScienceDirec](https://www.sciencedirect.com/science/article/pii/S2352340919306985?via%3Dihub) se encuentra una descripción de los datos, que ayudan un poco para entender qué significa cada atributo (ya que las siglas no son muy claras). Entonces, para la mejor comprensión de los atributos al usarlos en su estudio y aprendizaje se cambiaron sus nombres por los que se consideraban más claros.\n",
        "\n",
        "En general se puede concluir lo siguiente:\n",
        "\n",
        "- El conjunto de datos es viable, ya que no hay datos faltantes, hay pocos datos atípicos en la mayoría de los atributos y está balanceado de acuerdo con el atributo a predecir.\n",
        "- La principal dificultad que tiene el conjunto de datos es que varios atributos que deberían ser categóricos son numéricos (con \"datos intermedios\", es decir, con valores como 2.4 en vez de 2 o 3, por ejemplo).\n",
        "- No es necesario eliminar atributos, pues su correlación es muy poca.\n",
        "- Los datos atípicos presentes en el conjunto de datos no representan un problema ya que permite una diversidad de los datos, por ejemplo, en cuanto a edad o cantidad de comidas principales diarias que son útiles para la construcción del modelo.\n",
        "- Afortunadamente no hay valores nulos.\n",
        "- En principio se podría pensar en discretizar los atributos \"Day_Main_Meals\" y \"Vegetable_Frecuency\", ya que en su descripción son discretos, pero los datos no siguen esa especificación y se desconoce el motivo. Por lo tanto se mantienen, ya que al restringirlos a un rango menor de posibilidades, los modelos pueden sesgarse.\n",
        "- Es necesario eliminar los registros duplicados.\n",
        "- Es necesario normalizar los valores de los atributos ya que hay algunos atributos (como \"Weight\") muy variados de los demás.\n",
        "- Es necesario pasar los atributos categóricos a numéricos.\n",
        "- El conjunto de datos está balanceado en los distintos valores que puede tomar el atributo a predecir.\n",
        "\n",
        "### **Plan de ajuste de datos**\n",
        "1. Normalizar los valores de los atributos \"Age\" y \"Weight\".\n",
        "2. Pasar los atributos categóricos a numéricos.\n",
        "3. Eliminar los registros duplicados.\n",
        "4. Verificar la correlación entre los atributos para ver en qué se ha afectado al realizar las modificaciones.\n",
        "5. Verificar el balance de las clases para ver si se ha afectado al eliminar los duplicados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANQCRw-4q7sy"
      },
      "source": [
        "# **Pre-procesamiento de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u8-kj5njzdA"
      },
      "source": [
        "# Paso 1: Normalizar los valores de los atributos \"Age\" y \"Weight\"\n",
        "data['Age'] = scale(data['Age'])\n",
        "data['Weight'] = scale(data['Weight'])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4zZ6ScAmED1"
      },
      "source": [
        "# Paso 2: Pasar los atributos categóricos a numéricos\n",
        "categorize = data.apply(LabelEncoder().fit_transform)\n",
        "for i in categorical_att:\n",
        "    data[i] = categorize[i]\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwrOwHgfcEsY"
      },
      "source": [
        "# Paso 3: Eliminar los registros duplicados\n",
        "data.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0JSIjnDJZyu"
      },
      "source": [
        "# Paso 4: Verificar la correlación\n",
        "data.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QIrjg70ghx7"
      },
      "source": [
        "# Paso 5: Verificar el balance de las clases\n",
        "data['Obesity_Level'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kUi7JKbrLaA"
      },
      "source": [
        "# **Separar el conjunto de datos para entrenamiento y prueba**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xfBESF0rz_P"
      },
      "source": [
        "# Separación de datos\n",
        "X, y = data.drop('Obesity_Level', axis=1), data['Obesity_Level']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Listas para comparar las métricas de las diferentes técnicas\n",
        "precisions, recalls, fscores = [0,0,0,0], [0,0,0,0], [0,0,0,0]"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYtsZBDHx0Oy"
      },
      "source": [
        "# **Modelos de Clasificación**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5K4fF8htH7w"
      },
      "source": [
        "# Regresión Logística\n",
        "regression_model = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
        "regression_predict = regression_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1feiyTFuFBE"
      },
      "source": [
        "# K-vecinos más cercanos\n",
        "best, metrics, neighbors_best = 0, [0,0,0], None\n",
        "for k in range(3, 20):\n",
        "    neighbors_model = neighbors.KNeighborsClassifier(k, weights='uniform').fit(X_train, y_train)\n",
        "    neighbors_predict = neighbors_model.predict(X_test)\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, neighbors_predict, average='macro')\n",
        "    if (precision > metrics[0] or recall > metrics[1] or fscore > metrics[2]):\n",
        "        best, metrics, neighbors_best = k, [precision, recall, fscore], neighbors_predict\n",
        "print('El mejor valor de k es {0} con precisión {1:.10f}, recall {2:.10f} y fscore {3:.10f}'.format(best, metrics[0], metrics[1], metrics[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py2dq6_LyPN4"
      },
      "source": [
        "# Análisis Discriminante Lineal\n",
        "linear_model = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
        "linear_predict = linear_model.predict(X_test)"
      ],
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXiPthIQyP0d"
      },
      "source": [
        "# Análisis Discriminante Cuadrático\n",
        "quadratic_model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
        "quadratic_predict = quadratic_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B2VgABOyOSC"
      },
      "source": [
        "# **Matriz de confusión**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHu5f5gbytRc"
      },
      "source": [
        "# Matriz de confusión para Regresión Logística\n",
        "# print(confusion_matrix(y_test, regression_predict))\n",
        "heatmap(pd.crosstab(y_test, regression_predict, rownames=['Real'], colnames=['Predicted']), annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXMLnY9GzQr3"
      },
      "source": [
        "# Matriz de confusión para K-vecinos más cercanos\n",
        "# print(confusion_matrix(y_test, neighbors_best))\n",
        "heatmap(pd.crosstab(y_test, neighbors_best, rownames=['Real'], colnames=['Predicted']), annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2osx4oGEzR9u"
      },
      "source": [
        "# Matriz de confusión para Análisis Discriminante Lineal\n",
        "# print(confusion_matrix(y_test, linear_predict))\n",
        "heatmap(pd.crosstab(y_test, linear_predict, rownames=['Real'], colnames=['Predicted']), annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSsd6tk_zRn5"
      },
      "source": [
        "# Matriz de confusión para Análisis Discriminante Cuadrático\n",
        "# print(confusion_matrix(y_test, quadratic_predict))\n",
        "heatmap(pd.crosstab(y_test, quadratic_predict, rownames=['Real'], colnames=['Predicted']), annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5H2OjuV0BCj"
      },
      "source": [
        "# **Métricas de desempeño**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz3h3ASZ0Em8"
      },
      "source": [
        "# Métricas de desempeño para Regresión Logística\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, regression_predict, average='macro')\n",
        "print('Precision: {0:.5f}\\nRecall: {1:.5f}\\nF1-Score: {2:.5f}'.format(precision, recall, fscore))\n",
        "precisions[0], recalls[0], fscores[0] = precision, recall, fscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01HX1NkT0njG"
      },
      "source": [
        "# Métricas de desempeño para K-vecinos más cercanos\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, neighbors_best, average='macro')\n",
        "print('Precision: {0:.5f}\\nRecall: {1:.5f}\\nF1-Score: {2:.5f}'.format(precision, recall, fscore))\n",
        "precisions[1], recalls[1], fscores[1] = precision, recall, fscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WymmmnE0oHZ"
      },
      "source": [
        "# Métricas de desempeño para Análisis Discriminante Lineal\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, linear_predict, average='macro')\n",
        "print('Precision: {0:.5f}\\nRecall: {1:.5f}\\nF1-Score: {2:.5f}'.format(precision, recall, fscore))\n",
        "precisions[2], recalls[2], fscores[2] = precision, recall, fscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuNVoaLa0otY"
      },
      "source": [
        "# Métricas de desempeño para Análisis Discriminante Cuadrático\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, quadratic_predict, average='macro')\n",
        "print('Precision: {0:.5f}\\nRecall: {1:.5f}\\nF1-Score: {2:.5f}'.format(precision, recall, fscore))\n",
        "precisions[3], recalls[3], fscores[3] = precision, recall, fscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPD53RAPQ3C9"
      },
      "source": [
        "# **Análisis de los resultados**\n",
        "Tomando como referencia los resultados obtenidos se puede apreciar la diferencia entre las técnicas de clasificación, observando sus fortalezas y debilidades de la siguiente manera:\n",
        "\n",
        "- **Regresión Logística.** Esta técnica obtuvo buenos resultados al aplicarla al dataset correspondiente, aunque no fue la mejor, se pudo observar que sus métricas eran altas debido a que se basa en la relación directa entre los datos de entrada y el valor de salida. Como en este dataset en particular existe una relación muy estrecha entre lo que son los datos de entrada (hábitos, peso, altura, antecedentes familiares, etc.) y los datos de salida (nivel de obesidad), esta técnica se desempeña muy bien. Por otro lado, dado que este dataset es multiclase, el término \"linealmente separable\" aún se desconoce para verificar bien si la técnica funciona en este sentido.\n",
        "\n",
        "- **K-vecinos más cercanos.** La técnica es buena, ya que el dataset no es demasiado grande, y el cómputo de los k-vecinos no tiene una complejidad computacional alta. Por otro lado, ya que es una técnica de aproximación, no se garantiza que la predicción sea buena si la distancia euclidiana entre el dato a predecir y los demás, es lo suficientemente grande como para no lograr acertar en él.\n",
        "\n",
        "- **Análisis Discriminante Lineal.** Es una buena técnica ya que no se enfoca en buscar una aproximación al valor real que se quiere predecir, sino que se encarga de que el dato que predijo es el mejor, por lo que independientemente del dataset es una técnica recomendada para obtener mejores predicciones. Sin embargo, tiene una complejidad computacional alta (debido a la gran cantidad de operaciones que demanda la técnica desde el punto de vista matemático), aunque el dataset no es muy grande sí tiene un tamaño considerable para decidir entre elegir o no la técnica.\n",
        "\n",
        "- **Análisis Discriminante Cuadrático.** Aunque es una técnica eficaz para algunos casos, en el dataset estudiado no se obtuvo buenos resultados, ya que el valor a predecir poseía más de dos clases, esto provocó que el modelo se equivocara mucho más ya que este no está adaptado a las predicciones multiclase.\n",
        "\n",
        "Finalmente, teniendo en cuenta las anteriores consideraciones y las métricas de desempeño, la técnica más adecuada para este conjunto de modelos en particular es el *Análisis Discriminante Lineal*, como se puede observar en la siguiente gráfica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZRnHvUsK2Ek"
      },
      "source": [
        "# Comparación de las técnicas de clasificación\n",
        "techniques = ['Regresión Logística', 'K-vecinos más cercanos', \n",
        "              'Análisis Discriminante Lineal', 'Análisis Discriminante Cuadrático']\n",
        "pd.DataFrame({'Precision': precisions, 'Recall': recalls, 'F1-Score': fscores}, index=techniques).plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}